import os
import asyncio
import aiohttp
from aiogram import Bot, Dispatcher
from aiogram.types import Message
from src.embeddings.indexer import search

bot = Bot(token=os.getenv("TELEGRAM_TOKEN"))
dp = Dispatcher()

# –†–∞–∑–¥–µ–ª—å–Ω—ã–µ URL –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ —á–∞—Ç–∞
EMBED_URL = os.getenv("LMSTUDIO_BASE_URL", "http://localhost:1234/v1")
CHAT_URL = os.getenv("LMSTUDIO_BASE_URL", "http://localhost:1234/v1")
LLM_MODEL = os.getenv("LMSTUDIO_MODEL")

async def ask_lmstudio(question: str, context: str) -> str:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ LLM"""
    url = f"{CHAT_URL}/chat/completions"
    payload = {
        "model": LLM_MODEL,
        "messages": [
            {
                "role": "system", 
                "content": (
                    "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–æ–º–ø–∞–Ω–∏–∏ EORA, –æ—Ç–≤–µ—á–∞—é—â–∏–π —Å—Ç—Ä–æ–≥–æ –ø–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º. "
                    "–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∏–∂–µ. –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, —Å–∫–∞–∂–∏ '–ù–µ –∑–Ω–∞—é'."
                )
            },
            {
                "role": "user", 
                "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–í–æ–ø—Ä–æ—Å: {question}"
            }
        ],
        "temperature": 0.2,
        "max_tokens": 512
    }
    
    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=120)) as session:
        async with session.post(url, json=payload) as response:
            try:
                response.raise_for_status()
                data = await response.json()
                return data["choices"][0]["message"]["content"]
            except aiohttp.ClientResponseError as e:
                print(f"Chat API error: {e.status} {e.message}")
                return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞"
            except Exception as e:
                print(f"Unexpected error: {str(e)}")
                return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞"

@dp.message()
async def handle_message(message: Message):
    query = message.text.strip()
    if not query:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞")
        return
        
    # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    processing_msg = await message.answer("üîç –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏...")
    
    try:
        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –≤ FAISS
        chunks = await asyncio.to_thread(search, query, int(os.getenv("TOP_K", 4)))
        context_text = "\n---\n".join([c["text"] for c in chunks])
        
        if not context_text:
            await message.answer("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É")
            return
            
        # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
        await processing_msg.edit_text("ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
        
        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ LLM
        answer = await ask_lmstudio(query, context_text)
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞ (—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ)
        await processing_msg.edit_text(answer, parse_mode="Markdown")
    except Exception as e:
        print(f"Error handling message: {str(e)}")
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞")

async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    print("Starting Telegram bot...")
    asyncio.run(main())